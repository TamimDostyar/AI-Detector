{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_text_files = [\n",
    "    os.path.join('/app/data/humans_writing', 'essays_sorted.csv')\n",
    "]\n",
    "\n",
    "ai_text_files = [\n",
    "    os.path.join('/app/data/ai_generated', 'ai_generated_train_essays.csv'),\n",
    "    os.path.join('/app/data/ai_generated', 'ai_generated_train_essays_gpt-4.csv'),\n",
    "    os.path.join('/app/data/ai_generated', 'ai-essays.csv')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>essay</th>\n",
       "      <th>authors</th>\n",
       "      <th>source_url</th>\n",
       "      <th>thumbnail_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Addiction</td>\n",
       "      <td>Passion stabs, unrequited love hurts and taboo...</td>\n",
       "      <td>Omer Bonne means well; that much is certain. A...</td>\n",
       "      <td>Angela Chen</td>\n",
       "      <td>https://aeon.co//essays/how-far-should-medicin...</td>\n",
       "      <td>https://images.aeonmedia.co/images/4c7d125f-f4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Addiction</td>\n",
       "      <td>The fear of missing out haunts our social netw...</td>\n",
       "      <td>Here’s a test you might enjoy: rate these scen...</td>\n",
       "      <td>Jacob Burak</td>\n",
       "      <td>https://aeon.co//essays/can-we-break-free-from...</td>\n",
       "      <td>https://images.aeonmedia.co/images/1c3abfe6-af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Addiction</td>\n",
       "      <td>The neuroscientific picture of addiction overl...</td>\n",
       "      <td>Human beings crave all sorts of things: coffee...</td>\n",
       "      <td>Zoey Lavallee</td>\n",
       "      <td>https://aeon.co//essays/why-the-pull-of-addict...</td>\n",
       "      <td>https://images.aeonmedia.co/images/98330d80-eb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Addiction</td>\n",
       "      <td>The new science of addiction makes 12-step pro...</td>\n",
       "      <td>I hear a single voice as I walk up the steps t...</td>\n",
       "      <td>Rebecca Ruiz</td>\n",
       "      <td>https://aeon.co//essays/how-the-aa-is-out-of-s...</td>\n",
       "      <td>https://images.aeonmedia.co/images/a7bcbc8e-9c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Addiction</td>\n",
       "      <td>Cutting brings relief because emotion and pain...</td>\n",
       "      <td>Here’s what I remember about the first time I ...</td>\n",
       "      <td>Carrie Arnold</td>\n",
       "      <td>https://aeon.co//essays/how-self-harm-provokes...</td>\n",
       "      <td>https://images.aeonmedia.co/images/42f29e7a-fb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       title                                        description  \\\n",
       "0  Addiction  Passion stabs, unrequited love hurts and taboo...   \n",
       "1  Addiction  The fear of missing out haunts our social netw...   \n",
       "2  Addiction  The neuroscientific picture of addiction overl...   \n",
       "3  Addiction  The new science of addiction makes 12-step pro...   \n",
       "4  Addiction  Cutting brings relief because emotion and pain...   \n",
       "\n",
       "                                               essay        authors  \\\n",
       "0  Omer Bonne means well; that much is certain. A...    Angela Chen   \n",
       "1  Here’s a test you might enjoy: rate these scen...    Jacob Burak   \n",
       "2  Human beings crave all sorts of things: coffee...  Zoey Lavallee   \n",
       "3  I hear a single voice as I walk up the steps t...   Rebecca Ruiz   \n",
       "4  Here’s what I remember about the first time I ...  Carrie Arnold   \n",
       "\n",
       "                                          source_url  \\\n",
       "0  https://aeon.co//essays/how-far-should-medicin...   \n",
       "1  https://aeon.co//essays/can-we-break-free-from...   \n",
       "2  https://aeon.co//essays/why-the-pull-of-addict...   \n",
       "3  https://aeon.co//essays/how-the-aa-is-out-of-s...   \n",
       "4  https://aeon.co//essays/how-self-harm-provokes...   \n",
       "\n",
       "                                       thumbnail_url  \n",
       "0  https://images.aeonmedia.co/images/4c7d125f-f4...  \n",
       "1  https://images.aeonmedia.co/images/1c3abfe6-af...  \n",
       "2  https://images.aeonmedia.co/images/98330d80-eb...  \n",
       "3  https://images.aeonmedia.co/images/a7bcbc8e-9c...  \n",
       "4  https://images.aeonmedia.co/images/42f29e7a-fb...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "humans_dataframe =[]\n",
    "\n",
    "for file_path in human_text_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    humans_dataframe.append(df)\n",
    "\n",
    "humans_combined_essays = pd.concat(humans_dataframe, ignore_index=True)\n",
    "humans_combined_essays.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "READ AI FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d429f032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Advantages of Limiting Car Usage \\n\\nLimiting ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ce279be</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Advantages of Limiting Car Usage\\n\\nLimiting c...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c9595213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Limiting car usage has numerous advantages tha...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f2266d87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The passages provided discuss the advantages o...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eeace4bd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Title: The Advantages of Limiting Car Usage\\n\\...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  prompt_id                                               text  \\\n",
       "0  d429f032        0.0  Advantages of Limiting Car Usage \\n\\nLimiting ...   \n",
       "1  1ce279be        0.0  Advantages of Limiting Car Usage\\n\\nLimiting c...   \n",
       "2  c9595213        0.0  Limiting car usage has numerous advantages tha...   \n",
       "3  f2266d87        0.0  The passages provided discuss the advantages o...   \n",
       "4  eeace4bd        0.0  Title: The Advantages of Limiting Car Usage\\n\\...   \n",
       "\n",
       "   generated  \n",
       "0        1.0  \n",
       "1        1.0  \n",
       "2        1.0  \n",
       "3        1.0  \n",
       "4        1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_dataframes = []\n",
    "for file_path in ai_text_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    ai_dataframes.append(df)\n",
    "\n",
    "ai_generated_essays = pd.concat(ai_dataframes, ignore_index=True)\n",
    "\n",
    "ai_generated_essays.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "READ HUMANS ESSAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>essay</th>\n",
       "      <th>authors</th>\n",
       "      <th>source_url</th>\n",
       "      <th>thumbnail_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Addiction</td>\n",
       "      <td>Passion stabs, unrequited love hurts and taboo...</td>\n",
       "      <td>Omer Bonne means well; that much is certain. A...</td>\n",
       "      <td>Angela Chen</td>\n",
       "      <td>https://aeon.co//essays/how-far-should-medicin...</td>\n",
       "      <td>https://images.aeonmedia.co/images/4c7d125f-f4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Addiction</td>\n",
       "      <td>The fear of missing out haunts our social netw...</td>\n",
       "      <td>Here’s a test you might enjoy: rate these scen...</td>\n",
       "      <td>Jacob Burak</td>\n",
       "      <td>https://aeon.co//essays/can-we-break-free-from...</td>\n",
       "      <td>https://images.aeonmedia.co/images/1c3abfe6-af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Addiction</td>\n",
       "      <td>The neuroscientific picture of addiction overl...</td>\n",
       "      <td>Human beings crave all sorts of things: coffee...</td>\n",
       "      <td>Zoey Lavallee</td>\n",
       "      <td>https://aeon.co//essays/why-the-pull-of-addict...</td>\n",
       "      <td>https://images.aeonmedia.co/images/98330d80-eb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Addiction</td>\n",
       "      <td>The new science of addiction makes 12-step pro...</td>\n",
       "      <td>I hear a single voice as I walk up the steps t...</td>\n",
       "      <td>Rebecca Ruiz</td>\n",
       "      <td>https://aeon.co//essays/how-the-aa-is-out-of-s...</td>\n",
       "      <td>https://images.aeonmedia.co/images/a7bcbc8e-9c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Addiction</td>\n",
       "      <td>Cutting brings relief because emotion and pain...</td>\n",
       "      <td>Here’s what I remember about the first time I ...</td>\n",
       "      <td>Carrie Arnold</td>\n",
       "      <td>https://aeon.co//essays/how-self-harm-provokes...</td>\n",
       "      <td>https://images.aeonmedia.co/images/42f29e7a-fb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       title                                        description  \\\n",
       "0  Addiction  Passion stabs, unrequited love hurts and taboo...   \n",
       "1  Addiction  The fear of missing out haunts our social netw...   \n",
       "2  Addiction  The neuroscientific picture of addiction overl...   \n",
       "3  Addiction  The new science of addiction makes 12-step pro...   \n",
       "4  Addiction  Cutting brings relief because emotion and pain...   \n",
       "\n",
       "                                               essay        authors  \\\n",
       "0  Omer Bonne means well; that much is certain. A...    Angela Chen   \n",
       "1  Here’s a test you might enjoy: rate these scen...    Jacob Burak   \n",
       "2  Human beings crave all sorts of things: coffee...  Zoey Lavallee   \n",
       "3  I hear a single voice as I walk up the steps t...   Rebecca Ruiz   \n",
       "4  Here’s what I remember about the first time I ...  Carrie Arnold   \n",
       "\n",
       "                                          source_url  \\\n",
       "0  https://aeon.co//essays/how-far-should-medicin...   \n",
       "1  https://aeon.co//essays/can-we-break-free-from...   \n",
       "2  https://aeon.co//essays/why-the-pull-of-addict...   \n",
       "3  https://aeon.co//essays/how-the-aa-is-out-of-s...   \n",
       "4  https://aeon.co//essays/how-self-harm-provokes...   \n",
       "\n",
       "                                       thumbnail_url  \n",
       "0  https://images.aeonmedia.co/images/4c7d125f-f4...  \n",
       "1  https://images.aeonmedia.co/images/1c3abfe6-af...  \n",
       "2  https://images.aeonmedia.co/images/98330d80-eb...  \n",
       "3  https://images.aeonmedia.co/images/a7bcbc8e-9c...  \n",
       "4  https://images.aeonmedia.co/images/42f29e7a-fb...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "humans_dataframe =[]\n",
    "\n",
    "for file_path in human_text_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    humans_dataframe.append(df)\n",
    "\n",
    "humans_combined_essays = pd.concat(humans_dataframe, ignore_index=True)\n",
    "humans_combined_essays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "humans_essays = humans_combined_essays['essay']\n",
    "ai_essays = ai_generated_essays['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AI</th>\n",
       "      <th>Human</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Advantages of Limiting Car Usage \\n\\nLimiting ...</td>\n",
       "      <td>Omer Bonne means well; that much is certain. A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Advantages of Limiting Car Usage\\n\\nLimiting c...</td>\n",
       "      <td>Here’s a test you might enjoy: rate these scen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Limiting car usage has numerous advantages tha...</td>\n",
       "      <td>Human beings crave all sorts of things: coffee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The passages provided discuss the advantages o...</td>\n",
       "      <td>I hear a single voice as I walk up the steps t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Title: The Advantages of Limiting Car Usage\\n\\...</td>\n",
       "      <td>Here’s what I remember about the first time I ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  AI  \\\n",
       "0  Advantages of Limiting Car Usage \\n\\nLimiting ...   \n",
       "1  Advantages of Limiting Car Usage\\n\\nLimiting c...   \n",
       "2  Limiting car usage has numerous advantages tha...   \n",
       "3  The passages provided discuss the advantages o...   \n",
       "4  Title: The Advantages of Limiting Car Usage\\n\\...   \n",
       "\n",
       "                                               Human  \n",
       "0  Omer Bonne means well; that much is certain. A...  \n",
       "1  Here’s a test you might enjoy: rate these scen...  \n",
       "2  Human beings crave all sorts of things: coffee...  \n",
       "3  I hear a single voice as I walk up the steps t...  \n",
       "4  Here’s what I remember about the first time I ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "humans_essays.head()\n",
    "ai_essays.head()\n",
    "\n",
    "ai_and_humans_df =pd.DataFrame({'AI': ai_essays, 'Human': humans_essays})\n",
    "ai_and_humans_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3488 2235\n"
     ]
    }
   ],
   "source": [
    "print(len(ai_essays), len(humans_essays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "ai       3488\n",
      "human    2235\n",
      "Name: count, dtype: int64\n",
      "                                                text label\n",
      "0  Advantages of Limiting Car Usage \\n\\nLimiting ...    ai\n",
      "1  Advantages of Limiting Car Usage\\n\\nLimiting c...    ai\n",
      "2  Limiting car usage has numerous advantages tha...    ai\n",
      "3  The passages provided discuss the advantages o...    ai\n",
      "4  Title: The Advantages of Limiting Car Usage\\n\\...    ai\n"
     ]
    }
   ],
   "source": [
    "# Drop NaNs from each column and assign label\n",
    "ai_labeled = pd.DataFrame({'text': ai_essays.dropna(), 'label': 'ai'})\n",
    "human_labeled = pd.DataFrame({'text': humans_essays.dropna(), 'label': 'human'})\n",
    "\n",
    "# Combine\n",
    "training_df = pd.concat([ai_labeled, human_labeled], ignore_index=True)\n",
    "print(training_df['label'].value_counts())\n",
    "print(training_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    training_df['text'], training_df['label'], test_size=0.2, random_state=42, stratify=training_df['label']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Single Labeled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_labeled = pd.DataFrame({'text': ai_essays.dropna(), 'label': 'ai'})\n",
    "human_labeled = pd.DataFrame({'text': humans_essays.dropna(), 'label': 'human'})\n",
    "training_df = pd.concat([ai_labeled, human_labeled], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    training_df['text'],            # all essays\n",
    "    training_df['label'],           # 'ai' / 'human'\n",
    "    test_size=0.20,\n",
    "    random_state=42,\n",
    "    stratify=training_df['label']   # keep the same ai/human ratio\n",
    ")\n",
    "label_map = {'ai': 0, 'human': 1}\n",
    "y_train_num = y_train.map(label_map)\n",
    "y_test_num  = y_test.map(label_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase=True,\n",
    "    stop_words='english', \n",
    "    max_features=5000      # Limit to top 5k features for speed\n",
    ")\n",
    "\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train_vec, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ai       1.00      1.00      1.00       698\n",
      "       human       1.00      1.00      1.00       447\n",
      "\n",
      "    accuracy                           1.00      1145\n",
      "   macro avg       1.00      1.00      1.00      1145\n",
      "weighted avg       1.00      1.00      1.00      1145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.concat([\n",
    "    pd.DataFrame({'essay': ai_essays, 'label': 0}),     # 0 = AI\n",
    "    pd.DataFrame({'essay': humans_essays, 'label': 1})  # 1 = Human\n",
    "], ignore_index=True).dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Data & Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (4578, 300), Test shape: (1145, 300)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "MAX_NUM_WORDS = 10000\n",
    "MAX_SEQUENCE_LENGTH = 300\n",
    "\n",
    "# 1. Tokenize ALL essays using the whole dataset for consistency\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df['essay'].astype(str))\n",
    "\n",
    "# 2. Convert all essays to padded sequences\n",
    "all_sequences = tokenizer.texts_to_sequences(df['essay'].astype(str))\n",
    "all_padded = pad_sequences(all_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "\n",
    "# 3. Convert labels to numpy array if needed\n",
    "labels = df['label'].astype(int).values\n",
    "\n",
    "# 4. Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    all_padded, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Statistical baseline ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AI       1.00      1.00      1.00       698\n",
      "       Human       1.00      1.00      1.00       447\n",
      "\n",
      "    accuracy                           1.00      1145\n",
      "   macro avg       1.00      1.00      1.00      1145\n",
      "weighted avg       1.00      1.00      1.00      1145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. load your df with columns 'essay' (str) and 'label' (0=AI,1=Human)\n",
    "# assume df is already defined\n",
    "\n",
    "# 2. train/test split\n",
    "X_train_txt, X_test_txt, y_train, y_test = train_test_split(\n",
    "    df['essay'].astype(str), df['label'], \n",
    "    test_size=0.2, random_state=42, stratify=df['label']\n",
    ")\n",
    "\n",
    "# 3. turn text into TF-IDF features\n",
    "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "X_train_tf = tfidf.fit_transform(X_train_txt)\n",
    "X_test_tf  = tfidf.transform(X_test_txt)\n",
    "\n",
    "# 4. fit logistic regression\n",
    "stat_model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "stat_model.fit(X_train_tf, y_train)\n",
    "\n",
    "# 5. evaluate\n",
    "y_pred = stat_model.predict(X_test_tf)\n",
    "print(\"=== Statistical baseline ===\")\n",
    "print(classification_report(y_test, y_pred, target_names=['AI','Human']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and Train the Model | Deep-learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "144/144 [==============================] - 22s 144ms/step - loss: 0.2127 - accuracy: 0.9087 - val_loss: 0.0290 - val_accuracy: 0.9930\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 20s 137ms/step - loss: 0.0147 - accuracy: 0.9983 - val_loss: 0.0130 - val_accuracy: 0.9974\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 19s 134ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0361 - val_accuracy: 0.9895\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 19s 133ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.0024 - val_accuracy: 0.9991\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 19s 134ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0030 - val_accuracy: 0.9983\n",
      "\n",
      "=== Deep-learning model ===\n",
      "36/36 - 1s - loss: 0.0030 - accuracy: 0.9983 - 1s/epoch - 34ms/step\n",
      "36/36 [==============================] - 2s 37ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AI       1.00      1.00      1.00       698\n",
      "       Human       1.00      1.00      1.00       447\n",
      "\n",
      "    accuracy                           1.00      1145\n",
      "   macro avg       1.00      1.00      1.00      1145\n",
      "weighted avg       1.00      1.00      1.00      1145\n",
      "\n",
      "✅ Saved: dl_model.keras, tokenizer.joblib, tfidf_vectorizer.joblib, stat_model.joblib\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
    "\n",
    "# # hyper‐parameters\n",
    "# MAX_WORDS = 10000\n",
    "# MAX_LEN   = 300\n",
    "# EMB_DIM   = 128\n",
    "\n",
    "# # split as before\n",
    "# X_train_txt, X_test_txt, y_train, y_test = train_test_split(\n",
    "#     df['essay'].astype(str), df['label'], \n",
    "#     test_size=0.2, random_state=42, stratify=df['label']\n",
    "# )\n",
    "\n",
    "# # tokenize\n",
    "# tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<OOV>\")\n",
    "# tokenizer.fit_on_texts(X_train_txt)\n",
    "# train_seq = pad_sequences(tokenizer.texts_to_sequences(X_train_txt),\n",
    "#                           maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "# test_seq  = pad_sequences(tokenizer.texts_to_sequences(X_test_txt),\n",
    "#                           maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "\n",
    "# # build model\n",
    "# dl_model = Sequential([\n",
    "#     Embedding(input_dim=MAX_WORDS, output_dim=EMB_DIM, input_length=MAX_LEN),\n",
    "#     Bidirectional(LSTM(64, return_sequences=False)),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(32, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "# dl_model.compile(\n",
    "#     loss='binary_crossentropy',\n",
    "#     optimizer='adam',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# # train\n",
    "# history = dl_model.fit(\n",
    "#     train_seq, y_train,\n",
    "#     validation_data=(test_seq, y_test),\n",
    "#     epochs=5, batch_size=32\n",
    "# )\n",
    "\n",
    "# # evaluate\n",
    "# print(\"\\n=== Deep-learning model ===\")\n",
    "# dl_model.evaluate(test_seq, y_test, verbose=2)\n",
    "\n",
    "# # classification report\n",
    "# y_prob = dl_model.predict(test_seq).ravel()\n",
    "# y_pred = (y_prob > 0.5).astype(int)\n",
    "# print(classification_report(y_test, y_pred, target_names=['AI','Human']))\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "\n",
    "MAX_WORDS = 10000\n",
    "MAX_LEN   = 300\n",
    "EMB_DIM   = 128\n",
    "\n",
    "# build your TF‐IDF + logistic‐regression “statistical” model if you haven’t already:\n",
    "tfidf = TfidfVectorizer(max_features=MAX_WORDS, ngram_range=(1,2))\n",
    "X_stat = tfidf.fit_transform(df['essay'])\n",
    "stat_model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "stat_model.fit(X_stat, df['label'])\n",
    "\n",
    "# split for the deep‐learning model\n",
    "X_train_txt, X_test_txt, y_train, y_test = train_test_split(\n",
    "    df['essay'].astype(str), df['label'], \n",
    "    test_size=0.2, random_state=42, stratify=df['label']\n",
    ")\n",
    "\n",
    "# tokenize for DL\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train_txt)\n",
    "train_seq = pad_sequences(tokenizer.texts_to_sequences(X_train_txt),\n",
    "                          maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "test_seq  = pad_sequences(tokenizer.texts_to_sequences(X_test_txt),\n",
    "                          maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "\n",
    "# build your DL model\n",
    "dl_model = Sequential([\n",
    "    Embedding(input_dim=MAX_WORDS, output_dim=EMB_DIM, input_length=MAX_LEN),\n",
    "    Bidirectional(LSTM(64)),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "dl_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# train\n",
    "history = dl_model.fit(\n",
    "    train_seq, y_train,\n",
    "    validation_data=(test_seq, y_test),\n",
    "    epochs=5, batch_size=32\n",
    ")\n",
    "\n",
    "# evaluate & report\n",
    "print(\"\\n=== Deep-learning model ===\")\n",
    "dl_model.evaluate(test_seq, y_test, verbose=2)\n",
    "y_prob = dl_model.predict(test_seq).ravel()\n",
    "y_pred = (y_prob > 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred, target_names=['AI','Human']))\n",
    "\n",
    "# ————— now save everything —————\n",
    "# 1) deep-learning model in native Keras format\n",
    "dl_model.save('dl_model.keras')\n",
    "\n",
    "# 2) tokenizer (so you can recreate sequences later)\n",
    "joblib.dump(tokenizer,      'tokenizer.joblib')\n",
    "\n",
    "# 3) TF-IDF vectorizer + statistical model\n",
    "joblib.dump(tfidf,          'tfidf_vectorizer.joblib')\n",
    "joblib.dump(stat_model,     'stat_model.joblib')\n",
    "\n",
    "print(\"✅ Saved: dl_model.keras, tokenizer.joblib, tfidf_vectorizer.joblib, stat_model.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Inference on New Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2233\n",
      " Human   (66.81% confidence)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def classify_essay(text):\n",
    "    stat_p_human = stat_model.predict_proba(tfidf.transform([text]))[0,1]\n",
    "    seq         = tokenizer.texts_to_sequences([text])\n",
    "    padded      = pad_sequences(seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "    dl_p_human  = dl_model.predict(padded, verbose=0)[0,0]\n",
    "    p_human     = (stat_p_human + dl_p_human) / 2\n",
    "\n",
    "    if p_human > 0.5:\n",
    "        return \"Human\", p_human\n",
    "    else:\n",
    "        return \"AI\", 1 - p_human\n",
    "\n",
    "for sample in [\n",
    "    '''\n",
    "    9th January 2025\n",
    "The Evolution of Citizenship\n",
    "Citizenship represents a person's belonging, although its meaning has changed throughout history. Cooper describes citizenship as the intersection of equality and rights, which relates to integration ethics, differentiation ethics, and fragmentation ethics. Citizenship evolved as people fled war zones or sought better living conditions. This derives from ancient Greek and Roman civilizations, which developed within empires such as Rome rather than modern nation-states. Governments offered citizenship to provide rights and identification, allowing people to live freely and without fear of discrimination. \n",
    "Despite its promise, citizenship faces challenges in many countries. For example, dual citizenship raises questions of loyalty as citizens are expected to align with one nation’s cultural and political goals. The understanding of citizenship has varied among cultures as well. In medieval Europe, citizenship was linked to cities rather than nations, but monarchies and empires gradually redefined it. The British Empire, for instance, treated immigrants as part of the kingdom; however, rights were unequally distributed, and colonized people faced exclusion despite fighting for equality using the empire's ideals. The rise of capitalism further complicated citizenship by linking it to economic roles like property ownership or labor. Although poor workers were nominally considered equal citizens, systemic inequities persisted, sparking debates about fairness. Furthermore, movies show the challenges immigrants face due to citizenship, including deportation, job insecurity, language barriers, and uncertain futures. Religion has also influenced citizenship, often leading to violence and separating populations like the massacres aimed to remove entire Jewish communities. The Rwandan genocide, in the movie, shows how even diplomats, despite being from the same country, were stripped of their citizenship and targeted for extermination due to their perceived disloyalty and the actions of their fellow countrymen.\n",
    "In conclusion, citizenship is a dynamic and diverse concept that has evolved in response to historical, cultural, and political circumstances.\n",
    "    '''\n",
    "]:\n",
    "    label, conf = classify_essay(sample)\n",
    "    print(len(sample))\n",
    "    print(f\"{label:>6}   ({conf:.2%} confidence)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
